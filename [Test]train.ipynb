{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-08T08:20:59.634722Z",
     "start_time": "2024-06-08T08:20:58.509546Z"
    }
   },
   "source": [
    "import model.nn.esn as esn\n",
    "import Preprocessing.preprocessing as preprocessing\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model.nn import esn\n",
    "from model.utils.utils import prepare_target\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T08:20:59.639583Z",
     "start_time": "2024-06-08T08:20:59.636208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# WAV 파일이 있는 디렉토리\n",
    "wav_dir_train = '/Users/imdohyeon/Documents/PythonWorkspace/Lieon-ai/dataset/train'\n",
    "wav_files_train = [os.path.join(wav_dir_train, file) for file in os.listdir(wav_dir_train) if file.endswith('.wav')]\n",
    "\n",
    "wav_dir_test = '/Users/imdohyeon/Documents/PythonWorkspace/Lieon-ai/dataset/test'\n",
    "wav_files_test = [os.path.join(wav_dir_test, file) for file in os.listdir(wav_dir_test) if file.endswith('.wav')]"
   ],
   "id": "ec6c66f9bf1c7f58",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T08:20:59.643537Z",
     "start_time": "2024-06-08T08:20:59.640527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "데이터 로드 및 전처리, 데이터로더 생성\n",
    "\"\"\"\n",
    "# 데이터셋 생성\n",
    "train_dataset = preprocessing.WAVDataset(wav_files_train)\n",
    "test_dataset = preprocessing.WAVDataset(wav_files_test)\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ],
   "id": "c5e44d34a3fd29d1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T08:20:59.654245Z",
     "start_time": "2024-06-08T08:20:59.644982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "모델 정의, 학습 및 예측\n",
    "\"\"\"\n",
    "# ESN 모델 파라미터 정의\n",
    "input_size = 24  # feature 개수\n",
    "hidden_size = 100\n",
    "output_size = 1  # 출력 값이 0.5보다 작으면 클래스 0(거짓말 아님), 0.5보다 크면 클래스 1(거짓말)\n",
    "num_layers = 1  # Reservoir 개수\n",
    "leaking_rate = 0.2  # 값이 작을수록 이전 hidden 상태가 더 많이 유지\n",
    "spectral_radius = 0.9\n",
    "w_ih_scale = 1.0  # 첫 번째 레이어의 입력 가중치 스케일\n",
    "density = 1.0  # 순환 가중치 행렬의 밀도 (1이면 모든 요소가 nonzero)\n",
    "lambda_reg = 1e-4  # L2(Ridge) regularization 가중치(축소 파라미터) - 클 수록 강한 규제(과적합 방지)\n",
    "readout_training = 'svd'  # Readout 학습 알고리즘 지정 (svd, cholesky, inv, gd)\n",
    "output_steps = 'all'  # ridge regression 방법에서 reservoir 출력을 사용하는 방법 (last, all, mean)\n",
    "\n",
    "# ESN 모델 생성\n",
    "model = esn.ESN(input_size, hidden_size, output_size, num_layers=num_layers,\n",
    "            nonlinearity='tanh', leaking_rate=leaking_rate, spectral_radius=spectral_radius,\n",
    "            w_ih_scale=1.0, lambda_reg=lambda_reg, density=density, w_io=True, readout_training=readout_training, output_steps=output_steps)"
   ],
   "id": "65606c1597a18ce4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T08:21:16.350762Z",
     "start_time": "2024-06-08T08:21:00.876972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 학습 예제\n",
    "for batch_data, batch_washout, batch_targets in train_dataloader:\n",
    "    # 초기 hidden state 설정 (필요에 따라 None으로 두어도 됨)\n",
    "    h_0 = torch.zeros(esn.num_layers, batch_data.size(0), esn.hidden_size)\n",
    "\n",
    "    # ESN 모델에 데이터 전달\n",
    "    output, hidden = esn(batch_data, batch_washout, h_0, batch_targets)\n",
    "\n",
    "    # 손실 함수 및 최적화 알고리즘 정의 (여기서는 예제로 MSE 손실 사용)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(esn.parameters())\n",
    "\n",
    "    # 손실 계산 및 역전파\n",
    "    if output is not None:\n",
    "        loss = criterion(output, batch_targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # fit 함수 호출 (필요 시)\n",
    "    esn.fit()\n",
    "\n",
    "    print(f'Loss: {loss.item()}')\n"
   ],
   "id": "9227626aa3d6be33",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 163, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [21143, 23] at entry 0 and [32476, 23] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/10/mbcg1njx7fx5cgtqbk198z0m0000gn/T/ipykernel_4006/3463747969.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# 모델 학습 예제\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mbatch_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_washout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_targets\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0;31m# 초기 hidden state 설정 (필요에 따라 None으로 두어도 됨)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mh_0\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mesn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_layers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mesn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhidden_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    626\u001B[0m                 \u001B[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    627\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 628\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    629\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    630\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1331\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1332\u001B[0m                 \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_task_info\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1333\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1334\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1335\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_try_put_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1357\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_put_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1358\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mExceptionWrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1359\u001B[0;31m             \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreraise\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1360\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1361\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.7/site-packages/torch/_utils.py\u001B[0m in \u001B[0;36mreraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    541\u001B[0m             \u001B[0;31m# instantiate since we don't know how to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    542\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 543\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mexception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    544\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    545\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/Users/imdohyeon/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 163, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [21143, 23] at entry 0 and [32476, 23] at entry 1\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T08:12:39.033231Z",
     "start_time": "2024-06-08T08:12:39.033129Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fefb86ac0e1b0b01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test2",
   "id": "7a1358482252f2b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T07:47:45.690519Z",
     "start_time": "2024-06-09T07:47:45.681268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model.nn.esn import ESN\n",
    "from Preprocessing.preprocessing2 import create_dataloader\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "# WAV 파일이 있는 디렉토리\n",
    "wav_dir_train = '/Users/imdohyeon/Documents/PythonWorkspace/Lieon-ai/dataset/train'\n",
    "wav_files_train = [os.path.join(wav_dir_train, file) for file in os.listdir(wav_dir_train) if file.endswith('.wav')]\n",
    "\n",
    "wav_dir_test = '/Users/imdohyeon/Documents/PythonWorkspace/Lieon-ai/dataset/test'\n",
    "wav_files_test = [os.path.join(wav_dir_test, file) for file in os.listdir(wav_dir_test) if file.endswith('.wav')]\n",
    "\n",
    "\n",
    "max_length = 200  # Set maximum length for padding/truncating\n",
    "batch_size = 4\n",
    "leaking_rate = 1.0\n",
    "spectral_radius = 0.9\n",
    "lambda_reg = 1e-4\n",
    "washout = 10\n",
    "input_size = 23  # feature 개수\n",
    "hidden_size = 100\n",
    "output_size = 1  # 출력 값이 0.5보다 작으면 클래스 0(거짓말 아님), 0.5보다 크면 클래스 1(거짓말)\n",
    "num_layers = 1  # Reservoir 개수\n",
    "w_ih_scale = 1.0  # 첫 번째 레이어의 입력 가중치 스케일\n",
    "density = 1.0  # 순환 가중치 행렬의 밀도 (1이면 모든 요소가 nonzero)\n",
    "readout_training = 'svd'  # Readout 학습 알고리즘 지정 (svd, cholesky, inv, gd)\n",
    "output_steps = 'all'  # ridge regression 방법에서 reservoir 출력을 사용하는 방법 (last, all, mean)\n"
   ],
   "id": "590f2e757d4ed069",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T07:47:46.374622Z",
     "start_time": "2024-06-09T07:47:46.364670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataLoader\n",
    "dataloader = create_dataloader(wav_files_train, max_length, batch_size, shuffle=True)\n",
    "\n",
    "# Initialize ESN\n",
    "esn = ESN(input_size=input_size, hidden_size=hidden_size, output_size=output_size,\n",
    "          num_layers=num_layers, leaking_rate=leaking_rate, spectral_radius=spectral_radius,\n",
    "          lambda_reg=lambda_reg, batch_first=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "criterion = torch.nn.MSELoss()  # Example loss function\n",
    "optimizer = torch.optim.Adam(esn.parameters(), lr=1e-3)"
   ],
   "id": "d8eed7a6cacebcf",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T07:59:44.211893Z",
     "start_time": "2024-06-09T07:57:45.614904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in dataloader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Prepare washout for each sample in the batch\n",
    "        washout_tensor = torch.tensor([washout] * inputs.size(0))\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, _ = esn(inputs, washout_tensor)\n",
    "        \n",
    "        # Remove the washout period from the outputs and targets\n",
    "        outputs = outputs[:, washout:, :]\n",
    "        targets = targets[:, washout:]\n",
    "        \n",
    "        min_length = min(outputs.size(1), targets.size(1))\n",
    "        outputs = outputs[:, :min_length, :]  # Truncate outputs to min length\n",
    "        targets = targets[:, :min_length]     # Truncate targets to min length\n",
    "        \n",
    "        outputs = outputs.squeeze(-1) \n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ],
   "id": "8a68e3c4c3c41c53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.252281188964844\n",
      "Epoch 2/10, Loss: 3.964891195297241\n",
      "Epoch 3/10, Loss: 3.689911127090454\n",
      "Epoch 4/10, Loss: 3.427537679672241\n",
      "Epoch 5/10, Loss: 3.177931308746338\n",
      "Epoch 6/10, Loss: 2.941208600997925\n",
      "Epoch 7/10, Loss: 2.717440366744995\n",
      "Epoch 8/10, Loss: 2.506647825241089\n",
      "Epoch 9/10, Loss: 2.308809518814087\n",
      "Epoch 10/10, Loss: 2.1238598823547363\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T07:59:56.364105Z",
     "start_time": "2024-06-09T07:59:56.357048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the trained model\n",
    "torch.save(esn.state_dict(), 'esn_model_test.pth')"
   ],
   "id": "6634dac275d72d11",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2da57a0ea2bdcfa5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
